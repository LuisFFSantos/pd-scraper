import streamlit as st
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.service import Service as ChromeService
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from bs4 import BeautifulSoup
import os
import re
import pandas as pd
from io import BytesIO
from datetime import datetime
from webdriver_manager.chrome import ChromeDriverManager
from shutil import which


# Configura칞칚o da p치gina
st.set_page_config(
    page_title="Consulta Padr칚o",  # T칤tulo da aba do navegador
    page_icon="游댌"  # 칈cone da aba (emoji ou caminho para arquivo)
)

def get_driver():
    chrome_options = Options()
    chrome_options.add_argument("--headless=new")  # Executar em modo headless
    chrome_options.add_argument("--disable-gpu")  # Desativar GPU
    chrome_options.add_argument("--no-sandbox")  # Necess치rio para ambientes restritos
    chrome_options.add_argument("--disable-dev-shm-usage")  # Usar mem칩ria n칚o compartilhada
    chrome_options.add_argument("--disable-software-rasterizer")  # Evitar problemas gr치ficos
    chrome_options.add_argument("--remote-debugging-port=9222")  # Porta de depura칞칚o
    chrome_options.add_argument("--log-level=3")  # Minimizar logs desnecess치rios

    # Defina o caminho do Google Chrome no Windows
    chrome_path = "C:\\Program Files\\Google\\Chrome\\Application\\chrome.exe"
    chrome_options.binary_location = chrome_path

    # Verifique se o Chrome est치 dispon칤vel
    if not os.path.exists(chrome_path):
        st.error(f"O Chrome n칚o foi encontrado no caminho: {chrome_path}")
        return None

    st.write(f"Caminho do Chrome detectado: {chrome_path}")

    try:
        chrome_service = ChromeService(ChromeDriverManager().install())
        return webdriver.Chrome(service=chrome_service, options=chrome_options)
    except Exception as e:
        st.error(f"Erro ao configurar o driver do Chrome: {e}")
        raise





def scrape_with_catalog(keyword):
    link = f'https://store.usp.org/product/{keyword}'
    driver = get_driver()
    try:
        driver.get(link)
        WebDriverWait(driver, 20).until(
            EC.presence_of_element_located((By.CLASS_NAME, 'attr-value'))
        )

        page_source = driver.page_source
        soup = BeautifulSoup(page_source, 'html.parser')
        get = soup.find_all('div', attrs={"class": "usp-certificates"})
        lot_data = []

        for element in get:
            tbody = element.find('tbody')
            if tbody:
                for row in tbody.find_all('tr'):
                    lot_number = row.find_all('td')[0].text.strip()
                    valid_date = row.find_all('td')[2].text.strip()
                    lot_number_cleaned = re.sub(r'\s*\(.*?\)', '', lot_number)

                    # Formatando a data para o padr칚o brasileiro e traduzindo "Current" para "Vigente"
                    if "Current" in valid_date:
                        valid_date = "Vigente"
                    else:
                        try:
                            valid_date = datetime.strptime(valid_date, "%Y-%m-%d").strftime("%d/%m/%Y")
                        except ValueError:
                            try:
                                valid_date = datetime.strptime(valid_date, "%d-%b-%Y").strftime("%d/%m/%Y")
                            except ValueError:
                                valid_date = "Data Inv치lida"

                    # Criar link para download do certificado
                    certificate_url = f'https://static.usp.org/pdf/EN/referenceStandards/certificates/{keyword}-{lot_number_cleaned}.pdf'
                    lot_data.append((keyword, lot_number_cleaned, valid_date, certificate_url))

        return lot_data
    except Exception as e:
        st.error(f"Erro ao buscar dados para {keyword}: {e}")
        return []
    finally:
        driver.quit()

# Inicializar o estado da sess칚o
if 'results' not in st.session_state:
    st.session_state['results'] = []
if 'keywords' not in st.session_state:
    st.session_state['keywords'] = ""
if 'uploaded_file' not in st.session_state:
    st.session_state['uploaded_file'] = None
if 'reset_key' not in st.session_state:
    st.session_state['reset_key'] = 0
if 'history' not in st.session_state:
    st.session_state['history'] = []

# Interface principal
st.title("Consulta das validades dos Padr칫es USP")

# Sidebar para ajuda com componente expans칤vel
with st.sidebar:
    st.header("Ajuda")
    with st.expander("Exibir Passo a Passo"):
        st.markdown("""
        **Como usar este sistema:**
        1. Insira os c칩digos dos produtos separados por v칤rgula na 치rea de texto **ou** envie um arquivo Excel com os c칩digos.
        2. Clique no bot칚o **Buscar** para iniciar a consulta.
        3. Os resultados ser칚o exibidos em uma tabela com links para os certificados.
        4. Voc칡 pode baixar os resultados como um arquivo Excel.
        5. Clique em **Nova Consulta** para iniciar novamente.
        """)

# Input de c칩digos separados por v칤rgula
st.session_state['keywords'] = st.text_area("Insira os c칩digos dos produtos separados por v칤rgula:", value=st.session_state['keywords'])

# Upload de arquivo Excel
st.session_state['uploaded_file'] = st.file_uploader(
    "Ou envie um arquivo Excel com os c칩digos dos produtos:", type="xlsx", key=f"file_uploader_{st.session_state['reset_key']}"
)

# Defini칞칚o inicial de keywords
keywords = []

if st.session_state['uploaded_file']:
    try:
        df = pd.read_excel(st.session_state['uploaded_file'])
        keywords.extend(df[df.columns[0]].astype(str).tolist())
    except Exception as e:
        st.error(f"Erro ao carregar o arquivo Excel: {e}")

# Adiciona os c칩digos inseridos manualmente
if st.session_state['keywords']:
    keywords.extend(st.session_state['keywords'].split(','))

# Valida칞칚o de entrada
keywords = [str(k).strip() for k in keywords if str(k).strip()]

if st.button("Buscar"):
    st.session_state.results = []

    with st.spinner("Buscando informa칞칫es..."):
        for keyword in keywords:
            try:
                lot_data = scrape_with_catalog(keyword)
                st.session_state.results.extend(lot_data)
            except Exception as e:
                st.error(f"Erro ao buscar informa칞칫es para {keyword}: {e}")

    # Salvar resultados no hist칩rico
    if st.session_state.results:
        st.session_state['history'].append(st.session_state.results)

# Exibir resultados em tabela
if st.session_state.results:
    df_results = pd.DataFrame(st.session_state.results, columns=["C칩digo do Produto", "Lote", "Validade", "Certificado"])
    st.write("### Resultados da Pesquisa")

    # Adicionar links clic치veis na coluna "Certificado"
    df_results["Certificado"] = df_results["Certificado"].apply(lambda x: f'<a href="{x}" target="_blank">Baixar Certificado</a>')

    # Renderizar tabela com links HTML
    st.write(df_results.to_html(escape=False, index=False), unsafe_allow_html=True)

    # Exportar resultados para Excel
    buffer = BytesIO()
    df_results.to_excel(buffer, index=False)
    buffer.seek(0)

    st.download_button(
        label="Baixar Resultados em Excel",
        data=buffer,
        file_name="resultados_certificados.xlsx",
        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
    )

    # Bot칚o para limpar os resultados e redefinir os campos
    if st.button("Nova Consulta"):
        st.session_state['results'] = []
        st.session_state['keywords'] = ""
        st.session_state.pop('uploaded_file', None)
        st.session_state['reset_key'] += 1

# Exibir hist칩rico de consultas
if st.session_state['history']:
    with st.expander("Hist칩rico de Consultas"):
        for i, history in enumerate(st.session_state['history']):
            st.write(f"### Consulta {i + 1}")
            df_history = pd.DataFrame(history, columns=["C칩digo do Produto", "Lote", "Validade", "Certificado"])
            df_history["Certificado"] = df_history["Certificado"].apply(lambda x: f'<a href="{x}" target="_blank">Baixar Certificado</a>')
            st.write(df_history.to_html(escape=False, index=False), unsafe_allow_html=True)
